#!/usr/bin/env python3
"""
ë§ˆìŒë¡œê·¸ V4.0 - Claude â†” Neo4j AI íŒŒì´í”„ë¼ì¸ PoC
ì‹¤ì‹œê°„ ì§€ì‹ ìƒì„± ë° ì¶”ì¶œ íŒŒì´í”„ë¼ì¸ êµ¬í˜„
"""

import os
import sys
import json
from datetime import datetime
from typing import Dict, List, Any, Optional
from neo4j import GraphDatabase
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ClaudeNeo4jPipeline:
    """
    Claude AIì™€ Neo4j AuraDB ê°„ ì‹¤ì‹œê°„ ì§€ì‹ ìƒì„± íŒŒì´í”„ë¼ì¸
    """
    
    def __init__(self, instance_id="3e875bd7", username="neo4j", password=None):
        """ì´ˆê¸°í™”"""
        self.instance_id = instance_id
        self.uri = f"neo4j+s://{instance_id}.databases.neo4j.io"
        self.username = username
        self.password = password or os.getenv('NEO4J_PASSWORD')
        self.driver = None
        
        if not self.password:
            raise ValueError("NEO4J_PASSWORD í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def connect(self) -> bool:
        """AuraDB ì—°ê²°"""
        try:
            logger.info(f"ğŸ”Œ AuraDB íŒŒì´í”„ë¼ì¸ ì—°ê²°: {self.uri}")
            self.driver = GraphDatabase.driver(self.uri, auth=(self.username, self.password))
            
            with self.driver.session() as session:
                result = session.run("RETURN 'Claude-Neo4j Pipeline Active!' as status")
                status = result.single()["status"]
                logger.info(f"âœ… {status}")
                
            return True
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    def close(self):
        """ì—°ê²° ì¢…ë£Œ"""
        if self.driver:
            self.driver.close()
            logger.info("ğŸ”Œ íŒŒì´í”„ë¼ì¸ ì—°ê²° ì¢…ë£Œ")
    
    def log_development_activity(self, activity_data: Dict[str, Any]) -> bool:
        """
        ê°œë°œ í™œë™ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì§€ì‹ ê·¸ë˜í”„ì— ê¸°ë¡
        """
        try:
            with self.driver.session() as session:
                logger.info(f"ğŸ“ ê°œë°œ í™œë™ ê¸°ë¡: {activity_data.get('type', 'Unknown')}")
                
                if activity_data.get('type') == 'commit':
                    return self._log_git_commit(session, activity_data)
                elif activity_data.get('type') == 'file_creation':
                    return self._log_file_creation(session, activity_data)
                elif activity_data.get('type') == 'task_completion':
                    return self._log_task_completion(session, activity_data)
                elif activity_data.get('type') == 'knowledge_insight':
                    return self._log_knowledge_insight(session, activity_data)
                else:
                    logger.warning(f"âš ï¸  ì•Œ ìˆ˜ ì—†ëŠ” í™œë™ íƒ€ì…: {activity_data.get('type')}")
                    return False
                    
        except Exception as e:
            logger.error(f"âŒ ê°œë°œ í™œë™ ê¸°ë¡ ì‹¤íŒ¨: {e}")
            return False
    
    def _log_git_commit(self, session, data: Dict[str, Any]) -> bool:
        """Git ì»¤ë°‹ í™œë™ ê¸°ë¡"""
        session.run("""
            MERGE (commit:Commit {hash: $hash})
            SET commit.message = $message,
                commit.author = $author,
                commit.timestamp = datetime($timestamp),
                commit.files_changed = $files_changed,
                commit.lines_added = $lines_added,
                commit.lines_deleted = $lines_deleted,
                commit.activity_type = "development"
        """, **data)
        
        # ê°œë°œìì™€ ì—°ê²°
        session.run("""
            MATCH (commit:Commit {hash: $hash}), (dev:Developer {id: $author})
            MERGE (dev)-[:AUTHORED {timestamp: datetime($timestamp)}]->(commit)
        """, hash=data['hash'], author=data['author'], timestamp=data['timestamp'])
        
        logger.info(f"  âœ… Git ì»¤ë°‹ ê¸°ë¡: {data['hash'][:8]} - {data['message'][:50]}...")
        return True
    
    def _log_file_creation(self, session, data: Dict[str, Any]) -> bool:
        """íŒŒì¼ ìƒì„± í™œë™ ê¸°ë¡"""
        session.run("""
            MERGE (file:File {path: $path})
            SET file.name = $name,
                file.extension = $extension,
                file.size = $size,
                file.created = datetime($created),
                file.purpose = $purpose,
                file.complexity = $complexity
        """, **data)
        
        # ê°œë°œìì™€ ì—°ê²°
        if data.get('creator'):
            session.run("""
                MATCH (file:File {path: $path}), (dev:Developer {id: $creator})
                MERGE (dev)-[:CREATED {timestamp: datetime($created)}]->(file)
            """, path=data['path'], creator=data['creator'], created=data['created'])
        
        logger.info(f"  âœ… íŒŒì¼ ìƒì„± ê¸°ë¡: {data['name']}")
        return True
    
    def _log_task_completion(self, session, data: Dict[str, Any]) -> bool:
        """ì‘ì—… ì™„ë£Œ í™œë™ ê¸°ë¡"""
        session.run("""
            MERGE (task:Task {id: $task_id})
            SET task.name = $name,
                task.description = $description,
                task.status = $status,
                task.completion_date = datetime($completion_date),
                task.duration = $duration,
                task.complexity = $complexity
        """, **data)
        
        # ê°œë°œìì™€ ì—°ê²°
        if data.get('assignee'):
            session.run("""
                MATCH (task:Task {id: $task_id}), (dev:Developer {id: $assignee})
                MERGE (dev)-[:COMPLETED {
                    completion_date: datetime($completion_date),
                    effort: $effort
                }]->(task)
            """, task_id=data['task_id'], assignee=data['assignee'], 
                completion_date=data['completion_date'], effort=data.get('effort', 5))
        
        logger.info(f"  âœ… ì‘ì—… ì™„ë£Œ ê¸°ë¡: {data['name']}")
        return True
    
    def _log_knowledge_insight(self, session, data: Dict[str, Any]) -> bool:
        """ì§€ì‹ ì¸ì‚¬ì´íŠ¸ ê¸°ë¡"""
        session.run("""
            MERGE (insight:Insight {id: $insight_id})
            SET insight.title = $title,
                insight.description = $description,
                insight.category = $category,
                insight.confidence = $confidence,
                insight.generated = datetime($generated),
                insight.source = $source
        """, **data)
        
        # ê´€ë ¨ ê°œë…ê³¼ ì—°ê²°
        if data.get('related_concepts'):
            for concept in data['related_concepts']:
                session.run("""
                    MATCH (insight:Insight {id: $insight_id})
                    MERGE (concept:Concept {id: $concept_id})
                    ON CREATE SET concept.name = $concept_name
                    MERGE (insight)-[:RELATES_TO {strength: $strength}]->(concept)
                """, insight_id=data['insight_id'], concept_id=concept['id'], 
                    concept_name=concept['name'], strength=concept.get('strength', 5))
        
        logger.info(f"  âœ… ì§€ì‹ ì¸ì‚¬ì´íŠ¸ ê¸°ë¡: {data['title']}")
        return True
    
    def extract_knowledge_insights(self, query_type: str = "recent_activities") -> List[Dict[str, Any]]:
        """
        ì§€ì‹ ê·¸ë˜í”„ì—ì„œ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
        """
        try:
            with self.driver.session() as session:
                logger.info(f"ğŸ§  ì§€ì‹ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ: {query_type}")
                
                if query_type == "recent_activities":
                    return self._get_recent_activities(session)
                elif query_type == "developer_productivity":
                    return self._analyze_developer_productivity(session)
                elif query_type == "project_progress":
                    return self._analyze_project_progress(session)
                elif query_type == "knowledge_gaps":
                    return self._identify_knowledge_gaps(session)
                else:
                    logger.warning(f"âš ï¸  ì•Œ ìˆ˜ ì—†ëŠ” ì¿¼ë¦¬ íƒ€ì…: {query_type}")
                    return []
                    
        except Exception as e:
            logger.error(f"âŒ ì§€ì‹ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def _get_recent_activities(self, session) -> List[Dict[str, Any]]:
        """ìµœê·¼ í™œë™ ë¶„ì„"""
        result = session.run("""
            MATCH (dev:Developer)-[r]->(activity)
            WHERE type(r) IN ['AUTHORED', 'CREATED', 'COMPLETED']
            AND activity.timestamp IS NOT NULL
            RETURN dev.name as developer,
                   labels(activity)[0] as activity_type,
                   activity.timestamp as timestamp,
                   CASE 
                       WHEN 'Commit' IN labels(activity) THEN activity.message
                       WHEN 'File' IN labels(activity) THEN activity.name
                       WHEN 'Task' IN labels(activity) THEN activity.name
                       ELSE 'Unknown'
                   END as description
            ORDER BY activity.timestamp DESC
            LIMIT 10
        """)
        
        activities = []
        for record in result:
            activities.append({
                'developer': record['developer'],
                'type': record['activity_type'],
                'timestamp': str(record['timestamp']),
                'description': record['description']
            })
        
        logger.info(f"  ğŸ“Š ìµœê·¼ í™œë™ {len(activities)}ê°œ ì¶”ì¶œ")
        return activities
    
    def _analyze_developer_productivity(self, session) -> List[Dict[str, Any]]:
        """ê°œë°œì ìƒì‚°ì„± ë¶„ì„"""
        result = session.run("""
            MATCH (dev:Developer)-[r]->(activity)
            WHERE type(r) IN ['AUTHORED', 'CREATED', 'COMPLETED']
            WITH dev, count(r) as total_activities,
                 count(CASE WHEN 'Commit' IN labels(activity) THEN 1 END) as commits,
                 count(CASE WHEN 'File' IN labels(activity) THEN 1 END) as files_created,
                 count(CASE WHEN 'Task' IN labels(activity) THEN 1 END) as tasks_completed
            RETURN dev.name as developer,
                   dev.specialization as specialization,
                   total_activities,
                   commits,
                   files_created, 
                   tasks_completed
            ORDER BY total_activities DESC
        """)
        
        productivity = []
        for record in result:
            productivity.append({
                'developer': record['developer'],
                'specialization': record['specialization'],
                'total_activities': record['total_activities'],
                'commits': record['commits'],
                'files_created': record['files_created'],
                'tasks_completed': record['tasks_completed']
            })
        
        logger.info(f"  ğŸ“ˆ ê°œë°œì ìƒì‚°ì„± ë¶„ì„ {len(productivity)}ëª…")
        return productivity
    
    def _analyze_project_progress(self, session) -> List[Dict[str, Any]]:
        """í”„ë¡œì íŠ¸ ì§„í–‰ ìƒí™© ë¶„ì„"""
        result = session.run("""
            MATCH (project:Project)-[:USES_BRAIN]->(brain:System)
            MATCH (project)<-[:WORKS_ON|COMPLETED_STAGE]-(devs:Developer)
            OPTIONAL MATCH (project)<-[:PART_OF]-(achievements:Achievement)
            RETURN project.name as project_name,
                   project.current_phase as phase,
                   project.expected_roi as expected_roi,
                   brain.type as brain_type,
                   count(DISTINCT devs) as team_size,
                   count(DISTINCT achievements) as achievements_count
        """)
        
        progress = []
        for record in result:
            progress.append({
                'project': record['project_name'],
                'phase': record['phase'],
                'expected_roi': record['expected_roi'],
                'brain_type': record['brain_type'],
                'team_size': record['team_size'],
                'achievements': record['achievements_count']
            })
        
        logger.info(f"  ğŸ“Š í”„ë¡œì íŠ¸ ì§„í–‰ ë¶„ì„ {len(progress)}ê°œ")
        return progress
    
    def _identify_knowledge_gaps(self, session) -> List[Dict[str, Any]]:
        """ì§€ì‹ ê²©ì°¨ ì‹ë³„"""
        result = session.run("""
            MATCH (dev:Developer)
            OPTIONAL MATCH (dev)-[:HAS_SKILL]->(skills:Skill)
            OPTIONAL MATCH (dev)-[:LEARNED]->(concepts:Concept)
            WITH dev, count(DISTINCT skills) as skill_count, count(DISTINCT concepts) as concept_count
            WHERE skill_count < 5 OR concept_count < 3
            RETURN dev.name as developer,
                   dev.specialization as specialization,
                   skill_count,
                   concept_count,
                   CASE 
                       WHEN skill_count < 3 THEN 'Skill Development Needed'
                       WHEN concept_count < 2 THEN 'Knowledge Expansion Needed'
                       ELSE 'Moderate Gap'
                   END as gap_type
        """)
        
        gaps = []
        for record in result:
            gaps.append({
                'developer': record['developer'],
                'specialization': record['specialization'],
                'skill_count': record['skill_count'],
                'concept_count': record['concept_count'],
                'gap_type': record['gap_type']
            })
        
        logger.info(f"  ğŸ¯ ì§€ì‹ ê²©ì°¨ ì‹ë³„ {len(gaps)}ê°œ")
        return gaps
    
    def simulate_real_time_pipeline(self) -> bool:
        """
        ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜
        í˜„ì¬ ì‘ì—…ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì§€ì‹ ê·¸ë˜í”„ì— ë°˜ì˜
        """
        logger.info("ğŸ”„ ì‹¤ì‹œê°„ AI íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘...")
        
        try:
            # 1. í˜„ì¬ ì‘ì—… (Seed Content ë¡œë“œ) ê¸°ë¡
            current_task = {
                'type': 'task_completion',
                'task_id': 'auradb_seed_loading',
                'name': 'AuraDB Professional Seed Content ë¡œë”©',
                'description': 'Infrastructure AI ì„±ê³¼ë¥¼ ë°˜ì˜í•œ ì§€ì‹ ê·¸ë˜í”„ ì´ˆê¸°í™”',
                'status': 'completed',
                'completion_date': datetime.now().isoformat(),
                'duration': 30,  # ë¶„
                'complexity': 8,
                'assignee': 'code_architect_ai',
                'effort': 8
            }
            
            self.log_development_activity(current_task)
            
            # 2. íŒŒì¼ ìƒì„± ê¸°ë¡ (í˜„ì¬ íŒŒì´í”„ë¼ì¸ íŒŒì¼)
            pipeline_file = {
                'type': 'file_creation',
                'path': 'poc/ai_pipeline/claude_neo4j_pipeline.py',
                'name': 'claude_neo4j_pipeline.py',
                'extension': 'py',
                'size': 12000,  # ì˜ˆìƒ í¬ê¸°
                'created': datetime.now().isoformat(),
                'purpose': 'Claude-Neo4j ì‹¤ì‹œê°„ ì§€ì‹ ìƒì„± íŒŒì´í”„ë¼ì¸',
                'complexity': 9,
                'creator': 'code_architect_ai'
            }
            
            self.log_development_activity(pipeline_file)
            
            # 3. ì§€ì‹ ì¸ì‚¬ì´íŠ¸ ìƒì„±
            insight = {
                'type': 'knowledge_insight',
                'insight_id': 'ai_pipeline_breakthrough',
                'title': 'AI íŒŒì´í”„ë¼ì¸ ì‹¤ì‹œê°„ ì§€ì‹ ìƒì„± ëŒíŒŒêµ¬',
                'description': 'Claude AIì™€ Neo4j AuraDB ê°„ ì‹¤ì‹œê°„ ì—°ë™ìœ¼ë¡œ ê°œë°œ í™œë™ì´ ì¦‰ì‹œ ì§€ì‹ìœ¼ë¡œ ë³€í™˜ë˜ëŠ” í˜ì‹ ì  ì‹œìŠ¤í…œ êµ¬í˜„',
                'category': 'Technical Innovation',
                'confidence': 95,
                'generated': datetime.now().isoformat(),
                'source': 'Claude 4 Opus Max',
                'related_concepts': [
                    {'id': 'real_time_knowledge_generation', 'name': 'Real-time Knowledge Generation', 'strength': 10},
                    {'id': 'ai_pipeline_integration', 'name': 'AI Pipeline Integration', 'strength': 9},
                    {'id': 'graph_based_learning', 'name': 'Graph-based Learning', 'strength': 8}
                ]
            }
            
            self.log_development_activity(insight)
            
            # 4. ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ ë° ë¶„ì„
            logger.info("\nğŸ§  ì‹¤ì‹œê°„ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ:")
            
            recent_activities = self.extract_knowledge_insights("recent_activities")
            logger.info(f"ğŸ“Š ìµœê·¼ í™œë™ {len(recent_activities)}ê°œ:")
            for activity in recent_activities[:3]:  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                logger.info(f"  â€¢ {activity['developer']}: {activity['description']}")
            
            productivity = self.extract_knowledge_insights("developer_productivity")
            logger.info(f"ğŸ“ˆ ê°œë°œì ìƒì‚°ì„±:")
            for dev in productivity:
                logger.info(f"  â€¢ {dev['developer']}: ì´ {dev['total_activities']}ê°œ í™œë™")
            
            progress = self.extract_knowledge_insights("project_progress")
            logger.info(f"ğŸ“Š í”„ë¡œì íŠ¸ ì§„í–‰:")
            for proj in progress:
                logger.info(f"  â€¢ {proj['project']} ({proj['phase']}): {proj['team_size']}ëª… íŒ€")
            
            logger.info("âœ… ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ!")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ğŸš€ Claude-Neo4j AI íŒŒì´í”„ë¼ì¸ PoC ì‹œì‘")
    logger.info("=" * 60)
    
    pipeline = ClaudeNeo4jPipeline()
    
    try:
        # 1. ì—°ê²°
        if not pipeline.connect():
            return False
        
        # 2. ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜
        if not pipeline.simulate_real_time_pipeline():
            return False
        
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ‰ Claude-Neo4j AI íŒŒì´í”„ë¼ì¸ PoC ì„±ê³µ!")
        logger.info("âš¡ ì‹¤ì‹œê°„ ì§€ì‹ ìƒì„± íŒŒì´í”„ë¼ì¸ ê²€ì¦ ì™„ë£Œ")
        logger.info("ğŸ§  ê°œë°œ í™œë™ â†’ ì§€ì‹ ê·¸ë˜í”„ ìë™ ë³€í™˜ ì‹¤ì¦")
        logger.info("ğŸ”® ë§ˆìŒë¡œê·¸ V4.0ì˜ í•µì‹¬ ê¸°ëŠ¥ êµ¬í˜„ ì™„ë£Œ")
        logger.info("=" * 60)
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ PoC ì‹¤íŒ¨: {e}")
        return False
        
    finally:
        pipeline.close()

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)